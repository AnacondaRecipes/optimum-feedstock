{% set name = "optimum" %}
{% set version = "1.24.0" %}


package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  sha256: b502a2afbf78bb73370ebb1eff07b93108a1b386116e87eb17e882d210150551

build:
  number: 0
  # transformers >=4.26.0 is not available on s390x
  skip: true  # [s390x]
  skip: true  # [py<39]
  script:
    - {{ PYTHON }} -m pip install . --no-deps --no-build-isolation -vv
  entry_points:
    - optimum-cli = optimum.commands.optimum_cli:main

requirements:
  host:
    - pip
    - python
    - setuptools
    - wheel
  run:
    - python
    - transformers >=4.29
    - pytorch >=1.11
    - packaging
    - numpy
    - huggingface_hub >=0.8.0
  run_contrained:
    - onnxruntime >=1.11.0
    - datasets >=1.2.1
    - protobuf >=3.20.1
    - onnxruntime-gpu >=1.11.0
    - onnxruntime-training >=1.11.0
    - tensorflow >=2.4,<=2.12.1

test:
  imports:
    - optimum
  requires:
    - pip
  commands:
    - pip check
    - optimum-cli --help

about:
  home: https://github.com/huggingface/optimum
  summary: |
    ğŸ¤— Optimum is an extension of ğŸ¤— Transformers and Diffusers, providing a set of 
    optimization tools enabling maximum efficiency to train and run models on targeted hardware, 
    while keeping things easy to use.
  license: Apache-2.0
  license_file: LICENSE
  license_family: Apache
  description: |
    ğŸ¤— Optimum is an extension of Transformers that provides a set of performance optimization tools to train and run models on targeted hardware with maximum efficiency.
    The AI ecosystem evolves quickly, and more and more specialized hardware along with their own optimizations are emerging every day. 
    As such, Optimum enables developers to efficiently use any of these platforms with the same ease inherent to Transformers.
  doc_url: https://huggingface.co/docs/optimum/index
  dev_url: https://github.com/huggingface/optimum

extra:
  recipe-maintainers:
    - sugatoray
